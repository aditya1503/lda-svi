{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle, string, numpy, getopt, sys, random, time, re\n",
    "\n",
    "import onlineldavb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories=['sci.space','sci.electronics','rec.motorcycles','rec.sport.baseball']\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "#                                      categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters for SVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = len(categories) #Number of topics\n",
    "D = len(newsgroups_train.data) #Number of documents\n",
    "batchsize = 100\n",
    "num_iterations = 1000\n",
    "kappa = 0.9 #Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "def stem(sentance):\n",
    "    q = sentance.split()\n",
    "    s2= []\n",
    "    for i in q:\n",
    "        s2.append(ps.stem(i))\n",
    "    return ' '.join(s2)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "dat=[]\n",
    "sl=len(newsgroups_train.data)\n",
    "for i in newsgroups_train.data:\n",
    "    dat.append(stem(i))\n",
    "    if len(dat)%100==0:\n",
    "        print len(dat),sl\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"From: lerxst@wam.umd.edu (where' my thing) Subject: WHAT car is this!? Nntp-Posting-Host: rac3.wam.umd.edu Organization: Univers of Maryland, Colleg Park Lines: 15 I wa wonder if anyon out there could enlighten me on thi car I saw the other day. It wa a 2-door sport car, look to be from the late 60s/ earli 70s. It wa call a Bricklin. The door were realli small. In addition, the front bumper wa separ from the rest of the body. Thi is all I know. If anyon can tellm a model name, engin specs, year of production, where thi car is made, history, or whatev info you have on thi funki look car, pleas e-mail. Thanks, - IL ---- brought to you by your neighborhood Lerxst ----\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'equival are herebi'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem(\"equivalancies are hereby\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num vocab: 127316\n",
      "Most frequent: 127315\n",
      "Mean: 63657\n",
      "Std: 36752\n"
     ]
    }
   ],
   "source": [
    "def getVocab(vectorizer):\n",
    "    vocab = []\n",
    "    most_frequent = numpy.max(vectorizer.vocabulary_.values())\n",
    "    vocab_std = numpy.std(vectorizer.vocabulary_.values())\n",
    "    vocab_mean = numpy.mean(vectorizer.vocabulary_.values())\n",
    "\n",
    "    print \"Num vocab: %d\\nMost frequent: %d\\nMean: %d\\nStd: %d\" % \\\n",
    "        (len(vectorizer.vocabulary_), most_frequent, vocab_mean, vocab_std)\n",
    "\n",
    "    for key in vectorizer.vocabulary_:\n",
    "        if vectorizer.vocabulary_[key] > vocab_mean - vocab_std and \\\n",
    "            vectorizer.vocabulary_[key] < vocab_mean + vocab_std:\n",
    "            vocab.append(key)\n",
    "    return vocab\n",
    "\n",
    "vocab = getVocab(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num vocab: 127316\n",
      "Most frequent: 127315\n",
      "Mean: 63657\n",
      "Std: 36752\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "\n",
    "vectors = vectorizer.fit(dat)\n",
    "vocab = getVocab(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'equival'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem(u'equivalencies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v3={}\n",
    "for i in vocab:\n",
    "    v3[i]=stem(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rep(s3):\n",
    "    l2=[]\n",
    "    for i in s3.split():\n",
    "        l2.append(v3[i])\n",
    "    return ' '.join(l2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "u'From:'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-5dd0d3510fcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdat2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdat2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-0e75462a668e>\u001b[0m in \u001b[0;36mrep\u001b[0;34m(s3)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0ml2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0ml2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: u'From:'"
     ]
    }
   ],
   "source": [
    "dat2=[]\n",
    "for i in dat:\n",
    "    dat2.append(rep(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num vocab: 127316\n",
      "Most frequent: 127315\n",
      "Mean: 63657\n",
      "Std: 36752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stem(sentance):\n",
    "    q = sentance.split()\n",
    "    s2= []\n",
    "    for i in q:\n",
    "        s2.append(ps.stem(i))\n",
    "    return ' '.join(s2)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "dat=[]\n",
    "for i in newsgroups_train.data:\n",
    "    dat.append(stem(i))\n",
    "vectors = vectorizer.fit(dat)\n",
    "\n",
    "def getVocab(vectorizer):\n",
    "    vocab = []\n",
    "    most_frequent = numpy.max(vectorizer.vocabulary_.values())\n",
    "    vocab_std = numpy.std(vectorizer.vocabulary_.values())\n",
    "    vocab_mean = numpy.mean(vectorizer.vocabulary_.values())\n",
    "\n",
    "    print \"Num vocab: %d\\nMost frequent: %d\\nMean: %d\\nStd: %d\" % \\\n",
    "        (len(vectorizer.vocabulary_), most_frequent, vocab_mean, vocab_std)\n",
    "\n",
    "    for key in vectorizer.vocabulary_:\n",
    "        if vectorizer.vocabulary_[key] > vocab_mean - vocab_std and \\\n",
    "            vectorizer.vocabulary_[key] < vocab_mean + vocab_std:\n",
    "            vocab.append(key)\n",
    "    return vocab\n",
    "\n",
    "vocab = getVocab(vectorizer)\n",
    "\n",
    "# Our vocabulary\n",
    "# vocab = file('./dictnostops.txt').readlines()\n",
    "# vocab = [v.strip() for v in vocab]\n",
    "# W = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num vocab: 2200\n",
      "Most frequent: 2199\n",
      "Mean: 1099\n",
      "Std: 635\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "wds=pickle.load(open(\"semtrain.p\",'rb'))\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "dat=[]\n",
    "for i in wds:\n",
    "    dat.append(i[0])\n",
    "    dat.append(i[1])\n",
    "vectors = vectorizer.fit(dat)\n",
    "\n",
    "vocab = getVocab(vectorizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab=vectorizer.vocabulary_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource u'corpora/stopwords' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/Users/Mauceri/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-ff9cd17f22b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Mauceri/anaconda/lib/python2.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Mauceri/anaconda/lib/python2.7/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpora/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource u'corpora/stopwords' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/Users/Mauceri/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************"
     ]
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'LazyCorpusLoader' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-2f8f29641320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvoc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mvoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'LazyCorpusLoader' is not iterable"
     ]
    }
   ],
   "source": [
    "voc=[]\n",
    "for i in vocab.keys():\n",
    "    if i not in stopwords:\n",
    "        voc.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "def getbatch(size, iteration):\n",
    "    \n",
    "    sample_idx = sample(range(D), size)\n",
    "    return [newsgroups_train.data[i] for i in sample_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train LDA model using SVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: \n",
      "\t Num topics: 4 \n",
      "\t Num documents: 11314\n",
      "\t prior on weight vectors (theta): 0.25 \n",
      "\t prior on topics (beta): 0.25\n",
      "\t burn in rate: 1024.00 \n",
      "\t learning rate: 0.90\n",
      "Training iteration 0\n",
      "Training iteration 50\n",
      "Training iteration 100\n",
      "Training iteration 150\n",
      "Training iteration 200\n",
      "Training iteration 250\n",
      "Training iteration 300\n",
      "Training iteration 350\n",
      "Training iteration 400\n",
      "Training iteration 450\n",
      "Training iteration 500\n",
      "Training iteration 550\n",
      "Training iteration 600\n",
      "Training iteration 650\n",
      "Training iteration 700\n",
      "Training iteration 750\n",
      "Training iteration 800\n",
      "Training iteration 850\n",
      "Training iteration 900\n",
      "Training iteration 950\n",
      "Done training\n"
     ]
    }
   ],
   "source": [
    "kappa=0.9\n",
    "\n",
    "\n",
    "print \"Parameters: \\n\\t Num topics: %d \\n\\t Num documents: %d\" % (K, D)\n",
    "print \"\\t prior on weight vectors (theta): %4.2f \\n\\t prior on topics (beta): %4.2f\" % (1./K, 1./K)\n",
    "print \"\\t burn in rate: %4.2f \\n\\t learning rate: %4.2f\" % (1024., kappa)\n",
    "\n",
    "rho = []\n",
    "perplex = []\n",
    "olda = onlineldavb.OnlineLDA(vocab, K, D, 1./K, 1./K, 1024., 0.9)\n",
    "for iteration in range(0, num_iterations):\n",
    "    docset=getbatch(batchsize,iteration)\n",
    "    (gamma, bound) = olda.update_lambda(docset)\n",
    "    (wordids, wordcts) = onlineldavb.parse_doc_list(docset, olda._vocab,False)\n",
    "    perwordbound = bound * len(docset) / (D * sum(map(sum, wordcts)))\n",
    "    rho.append(olda._rhot,)\n",
    "    perplex.append(numpy.exp(-perwordbound))\n",
    "    \n",
    "    if (iteration % 50 == 0):\n",
    "        print \"Training iteration %d\" % iteration\n",
    "        \n",
    "\n",
    "            \n",
    "print \"Done training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import StopWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAF8CAYAAAAOzfv6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12324a050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(range(len(rho)), rho)\n",
    "# plt.ylabel('rho')\n",
    "# plt.xlabel('iteration')\n",
    "# plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(range(len(perplex)), perplex)\n",
    "plt.ylabel('held-out perplexity estimate')\n",
    "plt.xlabel('iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Print vocabulary per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2037",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-c09c800f3ad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'topic %d:'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_vocab_display\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'%20s  \\t---\\t  %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2037"
     ]
    }
   ],
   "source": [
    "num_vocab_display = 10\n",
    "\n",
    "for k in range(0, len(olda._lambda)):\n",
    "    lambdak = list(olda._lambda[k, :])\n",
    "    lambdak = lambdak / sum(lambdak)\n",
    "    temp = zip(lambdak, range(0, len(lambdak)))\n",
    "    temp = sorted(temp, key = lambda x: x[0], reverse=True)\n",
    "    print 'topic %d:' % (k)\n",
    "    for i in range(0, num_vocab_display):\n",
    "        print '%20s  \\t---\\t  %.4f' % (vocab[temp[i][1]], temp[i][0])\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Variational Inference w/ no Stochastisisty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: \n",
      "\t Num topics: 4 \n",
      "\t Num documents: 11314\n",
      "\t prior on weight vectors (theta): 0.25 \n",
      "\t prior on topics (beta): 0.25\n",
      "\t burn in rate: 1024.00 \n",
      "\t learning rate: 0.90\n",
      "Training iteration 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f524367a6f59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdocset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewsgroups_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0molda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mwordids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordcts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monlineldavb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_doc_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0molda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mperwordbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbound\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordcts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Mauceri/Dropbox/LDA-SVI/onlineldavb.pyc\u001b[0m in \u001b[0;36mupdate_lambda\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# mini-batch. This also returns the information about phi that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;31m# we need to update lambda.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msstats\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_e_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;31m# Estimate held-out likelihood for current values of lambda.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m#TODO: figure out what is meant by \"held-out\" here? (docs used to train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Mauceri/Dropbox/LDA-SVI/onlineldavb.pyc\u001b[0m in \u001b[0;36mdo_e_step\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;31m# the update for gamma gives this update. Cf. Lee&Seung 2001.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0mgammad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexpElogthetad\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                     \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcts\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mphinorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpElogbetad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m                 \u001b[0mElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgammad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mexpElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElogthetad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print \"Parameters: \\n\\t Num topics: %d \\n\\t Num documents: %d\" % (K, D)\n",
    "print \"\\t prior on weight vectors (theta): %4.2f \\n\\t prior on topics (beta): %4.2f\" % (1./K, 1./K)\n",
    "print \"\\t burn in rate: %4.2f \\n\\t learning rate: %4.2f\" % (1024., 0)\n",
    "\n",
    "rho = []\n",
    "perplex = []\n",
    "\n",
    "olda = onlineldavb.OnlineLDA(vocab, K, D, 1./K, 1./K, 1024., 0)\n",
    "for iteration in range(0, num_iterations):\n",
    "    docset=newsgroups_train.data\n",
    "    (gamma, bound) = olda.update_lambda(docset)\n",
    "    (wordids, wordcts) = onlineldavb.parse_doc_list(docset, olda._vocab,False)\n",
    "    perwordbound = bound * len(docset) / (D * sum(map(sum, wordcts)))\n",
    "    rho.append(olda._rhot,)\n",
    "    perplex.append(numpy.exp(-perwordbound))\n",
    "    \n",
    "    if (iteration % 50 == 0):\n",
    "        print \"Training iteration %d\" % iteration\n",
    "        \n",
    "\n",
    "            \n",
    "print \"Done training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(range(len(perplex)), perplex)\n",
    "plt.ylabel('held-out perplexity estimate')\n",
    "plt.xlabel('iteration')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
